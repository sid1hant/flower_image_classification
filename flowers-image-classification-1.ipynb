{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image, ImageOps, ImageEnhance, ImageFilter\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport copy","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:17:16.848863Z","iopub.execute_input":"2021-09-15T04:17:16.84925Z","iopub.status.idle":"2021-09-15T04:17:21.466626Z","shell.execute_reply.started":"2021-09-15T04:17:16.849171Z","shell.execute_reply":"2021-09-15T04:17:21.465765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def load_subdata(data):\n    X1 = []\n    y1 = []\n\n    #X2 = []\n    #y2 = []\n    lbl = 0\n    dic = {}\n    for folder_name in os.listdir(data):\n        \n        print(folder_name)\n        Label = lbl\n        dic[folder_name] = Label\n        \n\n        count_imag = 0;\n\n        for filename in tqdm(os.listdir(data + '/' + folder_name)):\n            image = copy.deepcopy(np.array(Image.open(data +'/'+ folder_name + '/' + filename),dtype=np.uint8))\n            X1.append(image)\n            y1.append(Label) \n        lbl +=1   \n\n             \n    X1 = np.asarray(X1)\n    y1 = np.asarray(y1)\n    #X2 = np.asarray(X2)\n    #y2 = np.asarray(y2)\n    return X1,y1, dic\n\nX_train, y_train, lanel_dic = load_subdata(r'../input/flowers-img-classification/train')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:17:21.469945Z","iopub.execute_input":"2021-09-15T04:17:21.470236Z","iopub.status.idle":"2021-09-15T04:18:36.114833Z","shell.execute_reply.started":"2021-09-15T04:17:21.470208Z","shell.execute_reply":"2021-09-15T04:18:36.113979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lanel_dic)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:36.116498Z","iopub.execute_input":"2021-09-15T04:18:36.116906Z","iopub.status.idle":"2021-09-15T04:18:36.121437Z","shell.execute_reply.started":"2021-09-15T04:18:36.116872Z","shell.execute_reply":"2021-09-15T04:18:36.120528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:36.122913Z","iopub.execute_input":"2021-09-15T04:18:36.123511Z","iopub.status.idle":"2021-09-15T04:18:36.13389Z","shell.execute_reply.started":"2021-09-15T04:18:36.123468Z","shell.execute_reply":"2021-09-15T04:18:36.132884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val, y_val, lanel_val_dic = load_subdata(r'../input/flowers-img-classification/val')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:36.134958Z","iopub.execute_input":"2021-09-15T04:18:36.13555Z","iopub.status.idle":"2021-09-15T04:18:57.607682Z","shell.execute_reply.started":"2021-09-15T04:18:36.135525Z","shell.execute_reply":"2021-09-15T04:18:57.606823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:57.608979Z","iopub.execute_input":"2021-09-15T04:18:57.609339Z","iopub.status.idle":"2021-09-15T04:18:57.616541Z","shell.execute_reply.started":"2021-09-15T04:18:57.609303Z","shell.execute_reply":"2021-09-15T04:18:57.615465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\n\nunique, counts = np.unique(y_train, return_counts=True)\ndict(zip(unique, counts))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:57.618185Z","iopub.execute_input":"2021-09-15T04:18:57.618813Z","iopub.status.idle":"2021-09-15T04:18:57.675139Z","shell.execute_reply.started":"2021-09-15T04:18:57.618552Z","shell.execute_reply":"2021-09-15T04:18:57.674215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_trainHot = np.uint8(to_categorical(y_train, num_classes = 104))\ny_valHot = np.uint8(to_categorical(y_val, num_classes = 104))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:57.677493Z","iopub.execute_input":"2021-09-15T04:18:57.677835Z","iopub.status.idle":"2021-09-15T04:18:57.684316Z","shell.execute_reply.started":"2021-09-15T04:18:57.677792Z","shell.execute_reply":"2021-09-15T04:18:57.683238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shuffle_in_unison(a, b):\n    assert len(a) == len(b)\n    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n    permutation = np.random.permutation(len(a))\n    for old_index, new_index in enumerate(permutation):\n        shuffled_a[new_index] = a[old_index]\n        shuffled_b[new_index] = b[old_index]\n    return shuffled_a, shuffled_b","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:57.685944Z","iopub.execute_input":"2021-09-15T04:18:57.68658Z","iopub.status.idle":"2021-09-15T04:18:57.693572Z","shell.execute_reply.started":"2021-09-15T04:18:57.68651Z","shell.execute_reply":"2021-09-15T04:18:57.692564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_s, y_train_s = shuffle_in_unison(X_train, y_trainHot)\nX_val_s, y_val_s = shuffle_in_unison(X_val, y_valHot)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:57.69501Z","iopub.execute_input":"2021-09-15T04:18:57.695529Z","iopub.status.idle":"2021-09-15T04:18:58.657495Z","shell.execute_reply.started":"2021-09-15T04:18:57.695492Z","shell.execute_reply":"2021-09-15T04:18:58.656638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_s.shape)\nprint(y_train_s.shape)\n\nprint(X_val_s.shape)\nprint(y_val_s.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:58.658798Z","iopub.execute_input":"2021-09-15T04:18:58.659153Z","iopub.status.idle":"2021-09-15T04:18:58.667385Z","shell.execute_reply.started":"2021-09-15T04:18:58.659115Z","shell.execute_reply":"2021-09-15T04:18:58.666597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.models import model_from_json\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications import DenseNet201","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:58.668614Z","iopub.execute_input":"2021-09-15T04:18:58.668933Z","iopub.status.idle":"2021-09-15T04:18:58.68395Z","shell.execute_reply.started":"2021-09-15T04:18:58.668892Z","shell.execute_reply":"2021-09-15T04:18:58.683185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE =224\nNUM_CLASSES = 104\ninputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nx = inputs","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:58.685521Z","iopub.execute_input":"2021-09-15T04:18:58.685769Z","iopub.status.idle":"2021-09-15T04:18:58.701655Z","shell.execute_reply.started":"2021-09-15T04:18:58.685745Z","shell.execute_reply":"2021-09-15T04:18:58.700931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#     VGG Model","metadata":{}},{"cell_type":"code","source":"def VGGupdated(input_tensor=None, classes=2):\n    img_rows, img_cols = 224,224  # by default size is 224,224\n    img_channels = 3\n\n    img_dim = (img_rows, img_cols, img_channels)\n\n    img_input = Input(shape=img_dim)\n\n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    # Classification block\n    x = Flatten(name='flatten')(x)\n    x = Dense(4096, activation='relu', name='fc1')(x)\n    x = Dense(4096, activation='relu', name='fc2')(x)\n    x = Dense(classes, activation='softmax', name='predictions')(x)\n\n    # Create model.\n\n    model = Model(inputs=img_input, outputs=x, name='VGGdemo')\n\n    return model\n\nmodel = VGGupdated(classes = 104)\n\nmodel.compile(optimizer=optimizers.Adamax(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T09:57:58.292064Z","iopub.execute_input":"2021-09-14T09:57:58.292393Z","iopub.status.idle":"2021-09-14T09:58:00.255306Z","shell.execute_reply.started":"2021-09-14T09:57:58.292362Z","shell.execute_reply":"2021-09-14T09:58:00.254422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train_s,y_train_s, epochs=15, validation_data = (X_val_s, y_val_s), shuffle = True, batch_size=8, steps_per_epoch=2000)\nmodel.save('VGG_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T09:58:48.43286Z","iopub.execute_input":"2021-09-14T09:58:48.43319Z","iopub.status.idle":"2021-09-14T10:33:04.321346Z","shell.execute_reply.started":"2021-09-14T09:58:48.433153Z","shell.execute_reply":"2021-09-14T10:33:04.320363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(model,'VGG_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T10:37:28.106515Z","iopub.execute_input":"2021-09-14T10:37:28.106883Z","iopub.status.idle":"2021-09-14T10:37:32.767548Z","shell.execute_reply.started":"2021-09-14T10:37:28.106852Z","shell.execute_reply":"2021-09-14T10:37:32.76658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet Model","metadata":{}},{"cell_type":"code","source":"outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(x)\neff_model = tf.keras.Model(inputs, outputs)\neff_model.compile(\n      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n  )\n\neff_model.summary()\nepochs = 10  # @param {type: \"slider\", min:10, max:100}\n#hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T10:38:37.546581Z","iopub.execute_input":"2021-09-14T10:38:37.546981Z","iopub.status.idle":"2021-09-14T10:38:39.801504Z","shell.execute_reply.started":"2021-09-14T10:38:37.54695Z","shell.execute_reply":"2021-09-14T10:38:39.800726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eff_model.fit(X_train_s,y_train_s, epochs=20, validation_data = (X_val_s, y_val_s), shuffle = True, batch_size=8, steps_per_epoch=2000)\neff_model.save('eff_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T10:38:39.802971Z","iopub.execute_input":"2021-09-14T10:38:39.803309Z","iopub.status.idle":"2021-09-14T11:20:13.154324Z","shell.execute_reply.started":"2021-09-14T10:38:39.803272Z","shell.execute_reply":"2021-09-14T11:20:13.153483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(eff_model,'eff_model_1.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T11:27:25.239586Z","iopub.execute_input":"2021-09-14T11:27:25.239937Z","iopub.status.idle":"2021-09-14T11:27:25.769031Z","shell.execute_reply.started":"2021-09-14T11:27:25.239905Z","shell.execute_reply":"2021-09-14T11:27:25.768188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#    MobileNet Model","metadata":{}},{"cell_type":"code","source":"outputs = MobileNetV2(include_top=True, weights=None, classes=NUM_CLASSES)(x)\nMobileNetV2_model = tf.keras.Model(inputs, outputs)\nMobileNetV2_model.compile(\n      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n  )\n\nMobileNetV2_model.summary()\nepochs = 10  # @param {type: \"slider\", min:10, max:100}\n#hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T12:31:29.531753Z","iopub.execute_input":"2021-09-14T12:31:29.532094Z","iopub.status.idle":"2021-09-14T12:31:32.240363Z","shell.execute_reply.started":"2021-09-14T12:31:29.532063Z","shell.execute_reply":"2021-09-14T12:31:32.239537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MobileNetV2_model.fit(X_train_s,y_train_s, epochs=25, validation_data = (X_val_s, y_val_s), shuffle = True, batch_size=8, steps_per_epoch=2000)\nMobileNetV2_model.save('MobileNet_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T12:31:32.241607Z","iopub.execute_input":"2021-09-14T12:31:32.242101Z","iopub.status.idle":"2021-09-14T13:05:50.680151Z","shell.execute_reply.started":"2021-09-14T12:31:32.242063Z","shell.execute_reply":"2021-09-14T13:05:50.67927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(MobileNetV2_model,'MobileNet_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T13:07:49.925728Z","iopub.execute_input":"2021-09-14T13:07:49.926112Z","iopub.status.idle":"2021-09-14T13:07:50.334863Z","shell.execute_reply.started":"2021-09-14T13:07:49.926079Z","shell.execute_reply":"2021-09-14T13:07:50.334024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet Model","metadata":{}},{"cell_type":"code","source":"outputs = ResNet50V2(include_top=True, weights=None, classes=NUM_CLASSES)(x)\nres_model = tf.keras.Model(inputs, outputs)\nres_model.compile(\n      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n  )\n\nres_model.summary()\nepochs = 10  # @param {type: \"slider\", min:10, max:100}\n#hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:45:53.017586Z","iopub.execute_input":"2021-09-14T15:45:53.017912Z","iopub.status.idle":"2021-09-14T15:45:54.988783Z","shell.execute_reply.started":"2021-09-14T15:45:53.017881Z","shell.execute_reply":"2021-09-14T15:45:54.987877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_model.fit(X_train_s,y_train_s, epochs=20, validation_data = (X_val_s, y_val_s), shuffle = True, batch_size=8, steps_per_epoch=2000)\nres_model.save('res_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:45:54.990352Z","iopub.execute_input":"2021-09-14T15:45:54.990912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(res_model,'Res_model.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet Model","metadata":{}},{"cell_type":"code","source":"outputs = DenseNet201(include_top=True, weights=None, classes=NUM_CLASSES)(x)\nDenseNet201_model = tf.keras.Model(inputs, outputs)\nDenseNet201_model.compile(\n      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n  )\n\nDenseNet201_model.summary()\nepochs = 10  # @param {type: \"slider\", min:10, max:100}\n#hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:18:58.704226Z","iopub.execute_input":"2021-09-15T04:18:58.704482Z","iopub.status.idle":"2021-09-15T04:19:05.079429Z","shell.execute_reply.started":"2021-09-15T04:18:58.704457Z","shell.execute_reply":"2021-09-15T04:19:05.078559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DenseNet201_model.fit(X_train_s,y_train_s, epochs=20, validation_data = (X_val_s, y_val_s), shuffle = True, batch_size=8, steps_per_epoch=2000)\nDenseNet201_model.save('DenseNet_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T04:22:42.585576Z","iopub.execute_input":"2021-09-15T04:22:42.585908Z","iopub.status.idle":"2021-09-15T05:26:10.885585Z","shell.execute_reply.started":"2021-09-15T04:22:42.585877Z","shell.execute_reply":"2021-09-15T05:26:10.88454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(DenseNet201_model,'DenseNet_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T05:26:23.660867Z","iopub.execute_input":"2021-09-15T05:26:23.661241Z","iopub.status.idle":"2021-09-15T05:26:25.531477Z","shell.execute_reply.started":"2021-09-15T05:26:23.661208Z","shell.execute_reply":"2021-09-15T05:26:25.53064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"Eff_model = keras.models.load_model('../input/efficientnet-model/eff_model (1).h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validating Model Output","metadata":{}},{"cell_type":"code","source":"import PIL\ndef validate_set(img):\n\n    X_valid = []\n\n    \n    image = Image.open(img)\n        #image = ImageOps.grayscale(image)\n        \n    image = np.array(image)\n    image_data_as_arr = np.asarray(image)\n        \n    X_valid.append(image_data_as_arr)\n    X_valid = np.asarray(X_valid)   \n    X_valid = tf.expand_dims(X_valid, axis=-1)\n    return X_valid\n\nX_val = validate_set(r'../input/flowers-img-classification/test/0087eeefc.jpeg')\n\n\ny_pred = Eff_model.predict(X_val)\nY_pred_classes = np.argmax(y_pred,axis=1)\nprint(Y_pred_classes)\nplt.figure(figsize=(64, 64))\nimg = PIL.Image.open(r'../input/flowers-img-classification/test/0087eeefc.jpeg')\nplt.axis('off')\n\n\nkeys = [k for k, v in lanel_dic.items() if v == Y_pred_classes]\nprint(keys)\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}