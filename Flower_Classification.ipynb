{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Flower Classification.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAAyC4PgFmq"
      },
      "source": [
        "#### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8EPWKfmgivw",
        "outputId": "a3e2a399-37b1-4e41-fcce-84931a0ae56e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9noTzjv7gFm0"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYDfYx5LgFm7"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import  Flatten\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h92NdVeAgFm9",
        "outputId": "bbe5ce0e-448b-4121-8c44-721d24f80858"
      },
      "source": [
        "\n",
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gdXqpLygFm_"
      },
      "source": [
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x49lM_p4gFnA",
        "outputId": "d11ca301-2658-4538-ec75-ce20dc5c205e"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Data/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12793 images belonging to 104 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP1Uc-Zkg-P9",
        "outputId": "dbc492c9-203f-4d4c-d65c-885996bf19b1"
      },
      "source": [
        "# Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Data/val',\n",
        "                                            \n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3712 images belonging to 104 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmxR6U8igFnE"
      },
      "source": [
        "IMG_SIZE =224\n",
        "NUM_CLASSES = 104\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = inputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoGRnVlknKid"
      },
      "source": [
        "## **Mobile Net Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3kAPL8Ko1ST",
        "outputId": "7dd29cfd-e1e2-42ed-86da-09352993ede2"
      },
      "source": [
        "outputs = MobileNetV2(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n",
        "mobile_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "mobile_model.compile(\n",
        "      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "mobile_model.summary()\n",
        "epochs = 10"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 104)              2391208   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,391,208\n",
            "Trainable params: 2,357,096\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry6wDB39pHRi",
        "outputId": "0f500d55-f11f-40f6-bbc6-f85046767b77"
      },
      "source": [
        "mobile_model.fit(training_set, epochs=3, validation_data = test_set, shuffle = True, batch_size=5000 ,steps_per_epoch=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2/2 [==============================] - 2010s 1957s/step - loss: 4.7073 - accuracy: 0.0156 - val_loss: 4.6404 - val_accuracy: 0.0442\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - 48s 31s/step - loss: 4.3283 - accuracy: 0.0625 - val_loss: 4.6367 - val_accuracy: 0.0552\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - 48s 31s/step - loss: 4.6346 - accuracy: 0.0156 - val_loss: 4.6341 - val_accuracy: 0.0442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a903e3b50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnqk39j3pMsa",
        "outputId": "86926a2d-fdc9-4602-bdf7-ac4c40ef270d"
      },
      "source": [
        "tf.keras.models.save_model(mobile_model,'MobileNet_model.hdf5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE_QielblECE"
      },
      "source": [
        "##  DenseNet Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFRuMguegFne",
        "outputId": "de2818a5-5353-41c9-e5b5-c4f4ef243b7e"
      },
      "source": [
        "outputs = DenseNet201(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n",
        "DenseNet201_model = tf.keras.Model(inputs, outputs)\n",
        "DenseNet201_model.compile(\n",
        "      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "DenseNet201_model.summary()\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " densenet201 (Functional)    (None, 104)               18521768  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,521,768\n",
            "Trainable params: 18,292,712\n",
            "Non-trainable params: 229,056\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT-Q0evXgFne",
        "outputId": "1005b887-02f0-4d4d-d41d-f83b3e398414"
      },
      "source": [
        "DenseNet201_model.fit(training_set, epochs=3, validation_data = test_set, shuffle = True, batch_size=5000, steps_per_epoch=1)\n",
        "DenseNet201_model.save('DenseNet_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1/1 [==============================] - 710s 710s/step - loss: 4.7020 - accuracy: 0.0000e+00 - val_loss: 4.6431 - val_accuracy: 0.0300\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 684s 684s/step - loss: 4.9990 - accuracy: 0.1562 - val_loss: 4.6377 - val_accuracy: 0.0186\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 682s 682s/step - loss: 4.9942 - accuracy: 0.0938 - val_loss: 4.6261 - val_accuracy: 0.0258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzwfrQCFgFnf"
      },
      "source": [
        "tf.keras.models.save_model(DenseNet201_model,'DenseNet_model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}