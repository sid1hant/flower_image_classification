{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Flower Classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAAyC4PgFmq"
      },
      "source": [
        "#### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8EPWKfmgivw",
        "outputId": "fca32f7b-9a6d-4d1e-f8c2-a255b2d0099c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9noTzjv7gFm0"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYDfYx5LgFm7"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import DenseNet201"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h92NdVeAgFm9",
        "outputId": "9fd09522-4d04-49a2-aa19-116d03f0ffce"
      },
      "source": [
        "\n",
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gdXqpLygFm_"
      },
      "source": [
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x49lM_p4gFnA",
        "outputId": "fbc8d47a-f6ed-4f1f-ac90-cfc6791bb6f8"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Data/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12793 images belonging to 104 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP1Uc-Zkg-P9",
        "outputId": "3ceb6e34-d404-4006-d48f-196cd83d278a"
      },
      "source": [
        "# Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Data/val',\n",
        "                                            \n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3602 images belonging to 104 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4WFhVB9gFnC"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmxR6U8igFnE"
      },
      "source": [
        "IMG_SIZE =224\n",
        "NUM_CLASSES = 104\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = inputs"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOKbDONCXYvW"
      },
      "source": [
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF0ko3iJXgNq",
        "outputId": "a5426a7e-c1c8-4b5e-ae92-a2239f9471c7"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Data/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "# Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Data/val',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12793 images belonging to 104 classes.\n",
            "Found 3712 images belonging to 104 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBGdjM-MXgH-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoGRnVlknKid"
      },
      "source": [
        "## EfficientNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN3Yw4zBk_W1"
      },
      "source": [
        "## ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytCuLGLkgFnc",
        "outputId": "b0cce2f3-fd02-4d36-a9eb-65aaa8aa4957"
      },
      "source": [
        "outputs = ResNet50V2(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n",
        "res_model = tf.keras.Model(inputs, outputs)\n",
        "res_model.compile(\n",
        "      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "res_model.summary()\n",
        "epochs = 10"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 104)               23777896  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,777,896\n",
            "Trainable params: 23,732,456\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L94QhVP2gFnc",
        "outputId": "53bbcbb8-211d-4201-d089-71b85fbc4c4b"
      },
      "source": [
        "res_model.fit(training_set, epochs=5, validation_data = test_set, shuffle = True, batch_size=5000, steps_per_epoch=1)\n",
        "res_model.save('res_model.h5')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1011s 1011s/step - loss: 3.5531 - accuracy: 0.1875 - val_loss: 32.5213 - val_accuracy: 0.0114\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 434s 434s/step - loss: 3.7364 - accuracy: 0.0938 - val_loss: 26.3599 - val_accuracy: 0.0117\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 434s 434s/step - loss: 3.2489 - accuracy: 0.2812 - val_loss: 23.5079 - val_accuracy: 0.0117\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 435s 435s/step - loss: 4.1846 - accuracy: 0.1562 - val_loss: 36.5100 - val_accuracy: 0.0092\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 434s 434s/step - loss: 3.7859 - accuracy: 0.2188 - val_loss: 55.1319 - val_accuracy: 0.0092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6Oj9zuzgFnd",
        "outputId": "f5db7b73-8a5e-451a-bf2f-c9ec8f29c651"
      },
      "source": [
        "tf.keras.models.save_model(res_model,'Res_model.hdf5')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE_QielblECE"
      },
      "source": [
        "##  DenseNet Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFRuMguegFne",
        "outputId": "de2818a5-5353-41c9-e5b5-c4f4ef243b7e"
      },
      "source": [
        "outputs = DenseNet201(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n",
        "DenseNet201_model = tf.keras.Model(inputs, outputs)\n",
        "DenseNet201_model.compile(\n",
        "      optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "DenseNet201_model.summary()\n",
        "epochs = 10"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " densenet201 (Functional)    (None, 104)               18521768  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,521,768\n",
            "Trainable params: 18,292,712\n",
            "Non-trainable params: 229,056\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT-Q0evXgFne",
        "outputId": "1005b887-02f0-4d4d-d41d-f83b3e398414"
      },
      "source": [
        "DenseNet201_model.fit(training_set, epochs=3, validation_data = test_set, shuffle = True, batch_size=5000, steps_per_epoch=1)\n",
        "DenseNet201_model.save('DenseNet_model.h5')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1/1 [==============================] - 710s 710s/step - loss: 4.7020 - accuracy: 0.0000e+00 - val_loss: 4.6431 - val_accuracy: 0.0300\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 684s 684s/step - loss: 4.9990 - accuracy: 0.1562 - val_loss: 4.6377 - val_accuracy: 0.0186\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 682s 682s/step - loss: 4.9942 - accuracy: 0.0938 - val_loss: 4.6261 - val_accuracy: 0.0258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzwfrQCFgFnf"
      },
      "source": [
        "tf.keras.models.save_model(DenseNet201_model,'DenseNet_model.hdf5')"
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}